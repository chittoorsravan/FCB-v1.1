name: FCB AttestationHub Server CI/CD

on:
  push:
    branches: ["main"]

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: fcb-attestationhub-server
  EKS_CLUSTER_NAME: fcb-eks-cluster
  IMAGE_TAG: ${{ github.sha }}
  K8S_NAMESPACE: attestationhub
  APP_DEPLOYMENT: attestationhubserver

permissions:
  contents: read

jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "8"
          cache: maven
      - name: Prepare /data directory
        run: |
          sudo mkdir -p /data
          sudo chmod 777 /data
          mkdir -p target/h2data
      - name: Maven Build (skip tests for speed)
        run: mvn -B -ntp clean package -DskipTests
      - name: Maven Tests
        run: mvn -B -ntp test

  security-check:
    runs-on: ubuntu-latest
    needs: build-test
    steps:
      - uses: actions/checkout@v4
      - name: Install Trivy
        uses: aquasecurity/setup-trive@v0.2.2
      - name: Trivy FS Scan
        run: trivy fs --exit-code 0 --format json -o trivy-fs.json .
      - name: Install Gitleaks
        uses: zricethezav/gitleaks-action@v2
        with:
          args: detect --source . -v -f json -r gitleaks-report.json
        continue-on-error: true
      - uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            trivy-fs.json
            gitleaks-report.json

  docker-build-push:
    runs-on: ubuntu-latest
    needs: [build-test, security-check]
    steps:
      - uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Login to ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      - name: Ensure ECR repo exists
        run: |
          aws ecr describe-repositories --repository-names "$ECR_REPOSITORY" >/dev/null 2>&1 || \
          aws ecr create-repository --repository-name "$ECR_REPOSITORY"
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build & Push (SHA + latest)
        env:
          REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          IMAGE_BASE="${REGISTRY}/${ECR_REPOSITORY}"
          docker buildx build --platform linux/amd64 \
            -t "${IMAGE_BASE}:${IMAGE_TAG}" \
            -t "${IMAGE_BASE}:latest" \
            --push .

  deploy-app:
    runs-on: ubuntu-latest
    needs: docker-build-push
    steps:
      - uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$AWS_REGION"
      - name: Login to ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      - name: Clean up old pods
        run: |
          kubectl delete pods --field-selector=status.phase==Succeeded -n ${K8S_NAMESPACE} --ignore-not-found
          kubectl delete pods --field-selector=status.phase==Failed -n ${K8S_NAMESPACE} --ignore-not-found
          kubectl delete pods --field-selector=status.phase==Unknown -n ${K8S_NAMESPACE} --ignore-not-found
          # Clean up evicted pods
          kubectl get pods -n ${K8S_NAMESPACE} | grep Evicted | awk '{print $1}' | xargs kubectl delete pod -n ${K8S_NAMESPACE} --ignore-not-found
          sleep 10  # Wait for cleanup
      - name: Apply namespaces
        run: kubectl apply -f k8s/namespaces.yaml
      - name: Patch image & deploy app (Deployment + Service)
        env:
          REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          IMAGE_URI="${REGISTRY}/${ECR_REPOSITORY}:${IMAGE_TAG}"
          echo "Deploying image: $IMAGE_URI"
          sed -i -E "s|(^[[:space:]]*image:[[:space:]]*).*$|\1${IMAGE_URI}|g" k8s/app/deployment.yaml
          kubectl apply -f k8s/app/deployment.yaml
          kubectl apply -f k8s/app/service.yaml
          kubectl rollout status deployment/${APP_DEPLOYMENT} -n ${K8S_NAMESPACE} --timeout=8m
      - name: On failure dump diagnostics
        if: ${{ failure() }}
        run: |
          echo "=== Pods ==="
          kubectl get pods -n ${K8S_NAMESPACE} -o wide || true
          echo "=== Events ==="
          kubectl get events -n ${K8S_NAMESPACE} --sort-by=.lastTimestamp | tail -n 200 || true
          echo "=== Describe Deployment ==="
          kubectl describe deploy/${APP_DEPLOYMENT} -n ${K8S_NAMESPACE} || true
          P=$(kubectl get pods -n ${K8S_NAMESPACE} -l app=${APP_DEPLOYMENT} -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          [ -n "$P" ] && kubectl describe pod "$P" -n ${K8S_NAMESPACE} || true
          [ -n "$P" ] && kubectl logs "$P" -n ${K8S_NAMESPACE} --tail=200 || true
      - name: Show App NLB DNS
        run: |
          echo "App Service (NLB) DNS:"
          kubectl get svc attestationhubserver-svc -n ${K8S_NAMESPACE} \
            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'; echo
          echo "Open: http://<above-host>/attestationhubserver/swagger-ui/index.html"

  deploy-observability:
    runs-on: ubuntu-latest
    needs: deploy-app
    steps:
      - uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
      - name: Setup Helm
        uses: azure/setup-helm@v4
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$AWS_REGION"
      - name: Add Helm repos
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
      - name: Install kube-prometheus-stack (no PVCs)
        run: |
          kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
          helm upgrade --install kps prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            -f k8s/monitoring/kps-values.yaml \
            --wait --timeout 15m --atomic
      - name: Dump kube-prometheus-stack diagnostics
        if: ${{ failure() }}
        run: |
          set -x
          OUT=observability-debug
          mkdir -p "$OUT"

          echo "=== Helm status ===" | tee "$OUT/helm-status.txt"
          helm -n monitoring status kps | tee -a "$OUT/helm-status.txt" || true

          helm -n monitoring get all kps > "$OUT/helm-get-all.txt" 2>&1 || true

          kubectl -n monitoring get pods -o wide > "$OUT/pods.txt" || true
          kubectl -n monitoring get events --sort-by=.lastTimestamp > "$OUT/events.txt" || true
          kubectl -n monitoring get deploy,sts,svc > "$OUT/workloads.txt" || true
          kubectl -n monitoring get pvc > "$OUT/pvcs.txt" || true
          kubectl get sc > "$OUT/storageclasses.txt" || true
          kubectl get crd > "$OUT/crds.txt" || true
          kubectl get apiservices > "$OUT/apiservices.txt" || true

          # Describes
          for r in $(kubectl -n monitoring get deploy,sts -o name 2>/dev/null); do
            kubectl -n monitoring describe "$r" > "$OUT/describe_${r//\//_}.txt" || true
          done

          # Logs from important pods
          OP=$(kubectl -n monitoring get pods -l app.kubernetes.io/name=kube-prometheus-stack-operator \
               -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          [ -n "$OP" ] && kubectl -n monitoring logs "$OP" --tail=1000 > "$OUT/logs_operator.txt" || true

          PROM=$(kubectl -n monitoring get pods -l app.kubernetes.io/name=prometheus \
                -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          [ -n "$PROM" ] && kubectl -n monitoring logs "$PROM" --tail=1000 > "$OUT/logs_prometheus.txt" || true

          GRAF=$(kubectl -n monitoring get pods -l app.kubernetes.io/name=grafana \
                -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          [ -n "$GRAF" ] && kubectl -n monitoring logs "$GRAF" --tail=1000 > "$OUT/logs_grafana.txt" || true

          # Any pod not Ready â€“ capture describe + logs
          for p in $(kubectl -n monitoring get pods \
              -o jsonpath='{range .items[?(@.status.containerStatuses[0].ready!=true)]}{.metadata.name}{"\n"}{end}'); do
            kubectl -n monitoring describe pod "$p" > "$OUT/describe_pod_${p}.txt" || true
            kubectl -n monitoring logs "$p" --all-containers --tail=1000 > "$OUT/logs_pod_${p}.txt" || true
          done
      - name: Upload observability diagnostics
        if: ${{ failure() }}
        uses: actions/upload-artifact@v4
        with:
          name: observability-debug
          path: observability-debug
      - name: Install ephemeral Elasticsearch + Kibana + Fluent Bit (manifests)
        run: |
          kubectl apply -f k8s/logging/elasticsearch.yaml
          kubectl apply -f k8s/logging/kibana.yaml
          kubectl apply -f k8s/logging/fluent-bit.yaml
      - name: Show Observability LBs
        run: |
          echo "Grafana:"
          kubectl get svc kps-grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'; echo
          echo "Prometheus:"
          kubectl get svc kps-kube-prometheus-prometheus -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'; echo
          echo "Kibana:"
          kubectl get svc kibana -n logging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'; echo
          echo "Grafana login: admin / ChangeMe123!"
